{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0 = neutral,                0 - нейтральність\n",
    "    1 = anger,                  1 - злість\n",
    "    2 = contempt,               2 - зневага\n",
    "    3 = disgust,                3 - огида \n",
    "    4 = fear,                   4 - страх\n",
    "    5 = happy,                  5 - радість \n",
    "    6 = sadness,                6 - сум \n",
    "    7 = surprise                7 - здивування "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy, move\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "if not os.listdir('sorted_data'):\n",
    "    print('No emotions within sorted_data detected. Creating new')\n",
    "    for em in emotions:\n",
    "        os.makedirs('sorted_data/'+em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_emotions = {t: em for t, em in enumerate(emotions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral',\n",
       " 1: 'anger',\n",
       " 2: 'contempt',\n",
       " 3: 'disgust',\n",
       " 4: 'fear',\n",
       " 5: 'happy',\n",
       " 6: 'sadness',\n",
       " 7: 'surprise'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all participants of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'src_images'\n",
    "annotations_path = 'src_labels'\n",
    "destination = 'sorted_data'\n",
    "\n",
    "raw_collector = []\n",
    "\n",
    "participants = os.listdir(img_path)\n",
    "labels = os.listdir(annotations_path)\n",
    "# Map emotions with folder names\n",
    "emo_map = dict(zip(emotions, [f'{k:03}' for k in range(7)]))\n",
    "\n",
    "for person in sorted(labels):\n",
    "    for emotion in os.listdir(os.path.join(annotations_path, person)):\n",
    "        emotion_path = os.path.join(annotations_path, person, emotion)\n",
    "        if os.listdir(emotion_path):\n",
    "            with open(os.path.join(emotion_path, os.listdir(emotion_path)[0]), 'r') as f:\n",
    "                sample = [os.listdir(emotion_path)[0], f.read()]\n",
    "                raw_collector.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = []\n",
    "\n",
    "for filename, emotion in raw_collector:\n",
    "    file_metadata = filename.split('_')\n",
    "    emotion = float(emotion.replace(' ', '').replace('e+00\\n', ''))\n",
    "    collector.append([file_metadata, emotion])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backup_0.csv', 'w') as f:\n",
    "    f.write(str(collector).replace('.0],', '\\n').replace('[', '').replace(']', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move images to appropriate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for [person, collection, img, ll], label in collector:\n",
    "    # Such a shit :)\n",
    "    assert label > 0, f'{person, collection} has neutral ({label}) label'\n",
    "    \n",
    "    path_to_img_folder = os.path.join(img_path, person, collection)\n",
    "    \n",
    "    images = sorted(os.listdir(path_to_img_folder))\n",
    "    # First 20% of images are neutral. The last (suppose 50%) are emotional.\n",
    "    n = len(images)\n",
    "    for i, image in enumerate(images, 1):\n",
    "        img_with_path = os.path.join(path_to_img_folder, image)\n",
    "        # Mark first 20% of images as neutral\n",
    "        if i / n <= 0.2:\n",
    "            copy(img_with_path, os.path.join(destination, encoded_emotions[0], image))\n",
    "        elif i / n >= 0.4:\n",
    "            copy(img_with_path, os.path.join(destination, encoded_emotions[int(label)], image))\n",
    "        # Mark last 50% of images as not neutral\n",
    "        #print(img_with_path, label, encoded_emotions[int(label)], round(100 * i / n, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to folders & throw out some images manually (especially from the neutral folder)\n",
    "\n",
    "\n",
    "\n",
    "After that pass all the images through the dlib keypoint detector to get all the facial points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../face_landmarks.dat')\n",
    "\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\", landmarks_count=68):\n",
    "    point = np.zeros((landmarks_count, 2), dtype=dtype)\n",
    "\n",
    "    for i in range(landmarks_count):\n",
    "        point[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return point\n",
    "\n",
    "\n",
    "def get_normalized_coords(shape, w, h):\n",
    "    face_landmarks = np.zeros(shape.shape)\n",
    "    \n",
    "    x_max = shape[:, 0].max()\n",
    "    y_max = shape[:, 1].max()\n",
    "    x_min = shape[:, 0].min()\n",
    "    y_min = shape[:, 1].min()\n",
    "    \n",
    "    face_landmarks[:, 0] = (x_max - shape[:, 0]) / (x_max - x_min)\n",
    "    face_landmarks[:, 1] = (y_max - shape[:, 1] / (y_max - y_min))\n",
    "    \n",
    "    return face_landmarks\n",
    "\n",
    "\n",
    "def get_radius_vector(norm_shape, x_c, y_c):\n",
    "    x, y = np.split(np.array(norm_shape), 2, axis=1)\n",
    "    return np.sqrt(np.square(x - x_c) + np.square(y - y_c))\n",
    "\n",
    "\n",
    "def get_angle(norm_shape):\n",
    "    x, y = np.split(np.array(norm_shape), 2, axis=1)\n",
    "    return np.arctan([x / y])\n",
    "\n",
    "\n",
    "def get_face_landmarks(img_name, img_array, predictor):\n",
    "    gray_image = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "    h, w = img_array.shape[:2]\n",
    "    rects = detector(gray_image, 1)\n",
    "#     rad_vectors = []\n",
    "#     face_landmarks = []\n",
    "    for i, rect in enumerate(rects):\n",
    "        if i > 1:\n",
    "            print(f'{img_name} seems to fail')\n",
    "            break\n",
    "        face_detector = predictor(gray_image, rect)\n",
    "        shape = shape_to_np(face_detector)\n",
    "        shape = get_normalized_coords(shape, w, h)\n",
    "        radius_vector = get_radius_vector(shape, w, h)\n",
    "        angle = get_angle(shape)\n",
    "\n",
    "        return shape, radius_vector, angle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install atpbar\n",
    "from atpbar import atpbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6362bcd90049a19533e045fbd79800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jsonlike = []\n",
    "for emotion in atpbar(emotions, name='images'):\n",
    "    for image in atpbar(os.listdir(os.path.join(destination, emotion)), name=emotion):\n",
    "        imgpath = os.path.join(destination, emotion, image)\n",
    "        try:\n",
    "            img_array = cv2.imread(imgpath)\n",
    "            face_landmarks, rad_vectors, angles = get_face_landmarks(image, img_array, predictor)\n",
    "        except:\n",
    "            print(f'failed on {imgpath}')\n",
    "            continue\n",
    "        \n",
    "        current_image_collector = {'image': image, 'emotion': emotion}\n",
    "\n",
    "        \n",
    "        #print(face_landmarks[0])\n",
    "        \n",
    "        for i, [x, y] in enumerate(face_landmarks):\n",
    "            current_image_collector.update({f'x_{i}':x})\n",
    "            current_image_collector.update({f'y_{i}':y})\n",
    "            current_image_collector.update({f'r_{i}':rad_vectors[i]})\n",
    "            current_image_collector.update({f'a_{i}':y})\n",
    "\n",
    "        jsonlike.append(current_image_collector)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(jsonlike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = df2['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(['emotion', 'image'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "pickle.dump(model, open('xgb_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored = pickle.load(open(\"xgb_model.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restored2 = pickle.load(open(\"xgb_with_rv.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring the original point coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = 100\n",
    "y_c = 100\n",
    "w = 200\n",
    "h = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "shape = []\n",
    "for k in range(0, len(X_sample), 3):\n",
    "    x = x_c - w * X_sample[k+1] \n",
    "    y = y_c - h * X_sample[k+2]\n",
    "    shape.append([x, y])\n",
    "x_s = [s[0] for s in shape]\n",
    "y_s = [s[1] for s in shape]\n",
    "\n",
    "plt.scatter(x_s, y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "rand_ar = np.array(X_sample).reshape(68,3)\n",
    "rand_ar = np.delete(rand_ar, obj=0, axis=1)\n",
    "\n",
    "rand_ar[:,0] = - x_c + w * rand_ar[:,0]\n",
    "rand_ar[:,1] = - y_c + h * rand_ar[:,1]\n",
    "\n",
    "plt.scatter(rand_ar[:,0], rand_ar[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_coordinates(norm_shape, x_c, y_c, w, h):\n",
    "    shape = np.array(norm_shape).reshape(68,3)\n",
    "    shape = np.delete(shape, obj=0, axis=1)\n",
    "\n",
    "    shape[:,0] = - x_c + w * rand_ar[:,0]\n",
    "    shape[:,1] = - y_c + h * rand_ar[:,1]\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_sample.reshape([1, 204]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_emotions[int(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
